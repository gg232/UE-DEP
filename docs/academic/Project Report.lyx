#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass report
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 5
\tocdepth 5
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Project Report
\end_layout

\begin_layout Author
Gerard Gallagher
\end_layout

\begin_layout Date
\begin_inset Preview

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
today
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Abstract
[insert abstract here]
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
addcontentsline{toc}{chapter}{Abstract}
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Project Objectives
\end_layout

\begin_layout Standard
This project will implement a digital effect pedal capable of loading and
 utilizing one or more user-supplied digital effects in the form of VST
 plugins.
 The main objective of this project is to produce a playable guitar effect
 pedal where the user can supply effects in the form of digital audio plugins.
 Previous attempts at such a pedal have been oriented towards lo-fi enthusiasts
 and DSP students who are comfortable coding their effects or significant
 portions of their system by hand.
 My design will attempt to make the approach as painless as possible for
 musicians and non-engineers, while retaining such “hackability” under the
 hood for audio engineers and DSP students.
 
\end_layout

\begin_layout Chapter
Technical Approach
\end_layout

\begin_layout Standard
The approach will be to use a Raspberry Pi 4 as a DSP unit, where the DSP
 algorithm is effectively specified and possibly modulated by the user 
\end_layout

\begin_layout Standard
Although the algorithms used by the user are in general (almost invariably)
 nonlinear, the device needs to be as linear as possible within its operating
 range.
 Colloquially, this translates to the requirement that the device imparts
 “no color of its own” upon audio signals.
 
\end_layout

\begin_layout Standard
I have decided to move input and output sampling frequencies to 44.1kHz because
 it is plausible that the user might want to pitch-shift their performance
 by up to a few octaves, so a sample rate that can cover the entire audible
 frequency spectrum is required.
 The Raspberry Pi’s I2S hardware will provide the audio clock, and because
 it is generated by the Pi, it is controlled by the Pi and can be set through
 software.
 The ADC and DAC can both handle frequencies as low as 8kHz and as high
 as 384kHz, so I’ll make sure to try them during the testing phase, but
 preliminary tests have shown that the Raspberry Pi 4B can handle processing
 several effects (albeit from a USB audio interface) with a sample frequency
 of 44.1kHz.
\end_layout

\begin_layout Standard
Except for the RF filter on the input, all other filters will be active.
 The RF filter will be a simple RC passive filter designed to block RF interfere
nce.
 At the input, all audio input signals will go through a high-pass centered
 below 20Hz to kill DC from input sources and remove garbage (unwanted signal
 energy) from below the threshold of audibility.
 The output will have an anti-imaging low-pass filter with an output impedance
 similar to those exhibited by other guitar pedals.
 There will not be an audio high-pass at this stage.
 
\end_layout

\begin_layout Standard
I admittedly spent far too long obsessing over filter types and transfer
 functions to conclude that, because of the modern sigma-delta ADC and DAC
 architectures that naturally oversample the signal, the required specifications
 for the anti-aliasing filter are rather generous towards the designer.
 Even a competently designed passive RC filter would suffice.
\end_layout

\begin_layout Standard
The preamp will be adjustable for the user by a potentiometer mounted to
 the exterior of the device.
 Although most electric instruments have a volume knob, I would like to
 give the user the ability to specify the gain needed (by ear + clipping
 LED) when the instrument’s volume knob is at maximum gain, so that they
 can set the headroom of the preamp-ADC combo to suit their playing style
 and particular instrument.
 
\end_layout

\begin_layout Standard
I have used the terminology “flat” several times without further specification.
 This will now be done.
 In signals and systems, a flat frequency response is one where the frequency
 response is constant up to infinity, and the phase response is perfectly
 linear up to infinity .
 This is impossible to build, but even if we allow for responses that are
 flat only in the passband, this is still a stringent specification for
 my system to respond to.
 The frequency response is known to affect the tonal quality of a sound,
 and it is through the idea of “balancing frequencies” that filtering is
 taught to audio engineers in recording schools.
 However, the subject of the audibility of phase response is controversial
 and steeped in misinformation.
 Basically, “reasonable” amounts of phase distortion are not audible when
 applied to regular music in typical settings.
 It can be heard if applied to sufficiently chosen test signals, and in
 anechoic chambers.
 The seminal paper on the issue, "On the Audibility of Midrange Phase Distortion
 in Audio Systems" by Lipshitz, et.
 al.
 , states the following four findings (emphasis is mine):
\end_layout

\begin_layout Enumerate
Even quite small midrange phase nonlinearities can be audible on suitably
 chosen signals.
 
\end_layout

\begin_layout Enumerate
Audibility is far greater on headphones than on loudspeakers.
\end_layout

\begin_layout Enumerate
Simple acoustic signals generated anechoically display clear phase audibility
 on headphones.
\end_layout

\begin_layout Enumerate
On normal music or speech signals phase distortion appears not to be generally
 audible, although it was heard with 99% confidence on some recorded vocal
 material.
\end_layout

\begin_layout Standard
The focus of my design is guitar signals.
 Although it is plausible that a user might plug a microphone into my design,
 vocal performances are not the focus of the project, and there already
 exist several better-adapted units for vocalists.
 To be more quantitative about this, I cite the following graph published
 as part of the study by Hansen and Madsen:
\end_layout

\begin_layout Standard
[insert image here]
\end_layout

\begin_layout Standard
Predictably, the tolerance for phase distortion is lowest around the audio
 midrange, where human voices are center, and increases with frequency.
 As amplitude level increases, the tolerance also decreases across the board,
 but still seems to approach 30 degrees at some point in the audible band
 as frequencies fall to zero or rise to 20kHz.
 A caveat of this study is that it was conducted at “reasonable” levels,
 and guitar amplifiers are invariably “unreasonably loud,” specifically
 much louder than the levels participants were subjected to in this study.
 Additionally, it was tested with sine waves.
 
\end_layout

\begin_layout Standard
The short version of the above is that phase distortion should be kept low,
 but a little bit towards the limits of the audible band is acceptable.
 Specifically, if I keep it under about 5 degrees, then it should be unnoticeabl
e for all practical purposes.
 The more noticeable problem will be, in my view, the frequency response
 of my filters, which needs to be as flat as possible in the passband.
 
\end_layout

\begin_layout Standard
Fortunately, filters with flatness of either frequency or phase response
 in the passband is very much a solved problem.
 A Bessel filter has a maximally flat phase response in the passband, whereas
 a Butterworth filter has a maximally flat frequency response.
 The Bessel filter’s frequency response does attenuate the upper frequencies
 in the passband, whereas the Butterworth filter’s phase response does distort
 the phase in the upper frequencies of the passband.
 The Bessel filter’s frequency response and Butterworth filter’s phase response
 are both monotonic .
 For audio purposes, a monotonic roll-off is better than one that is not
 monotonic, because such filters sound more natural.
 The main problem with using the Bessel filter is that it has a slow stopband
 roll-off, and the roll-off can be audible in the passband for low-order
 filters.
 For the high-pass filter input, because phase distortion is more acceptable
 in the lowest extremes of the audible band, I will use a 2nd-order Butterworth
 transfer function.
 For the low-pass filter, I will use a 3rd-order Butterworth transfer function
 because of the previous reason, but more importantly to ensure that the
 filter attenuates any supersonic frequencies that could alias down into
 the audible band upon sampling.
 The output low-pass will be a higher-order Butterworth filter, because
 I would like to accommodate users who want to shift their sounds close
 to the threshold of audibility.
 
\end_layout

\begin_layout Standard
Because the filters are active filters with cutoffs separated by (far more
 than) an octave, it is permissible to design them independently and then
 cascade them, as opposed to designing a narrowband asymmetrical bandpass.
 I mulled over adding a notch at 60Hz to deal with ground hum, but decided
 against it for two reasons.
 Firstly, a digital notch could be trivially implemented by the user through
 an EQ plugin.
 Secondly, it is plausible that a guitarist might want to play notes near
 60Hz, and even a properly designed notch could intrude in that space.
 A better solution is a toggleable ground lift .
 As soon as possible in the signal chain.
\end_layout

\begin_layout Standard
Although active filters should theoretically commute, because one of my
 filters will also be an amplifier, and for impedance matching purposes,
 it is better to amplify a filtered signal.
 If the signal is amplified first, it has a higher chance of clipping the
 filter’s op-amp.
\end_layout

\begin_layout Standard
The gain stage will also have a limiter circuit before the first op-amp
 and an LED indicator that flashes when the signal clips.
 The single-ended ADC has a full-scale value of 3V, so all signals must
 lie between 0V and 3V, or else they will be (horribly) distorted by clipping
 off the peaks.
 My approach here will be to implement a hard limiter at 3V exactly, but
 to allow the actual op-amp some extra headroom.
 My reasoning is that, although we are taught in introductory circuit courses
 that op-amps are perfectly linear except for outside their ranges of saturation
, the truth of the matter is that they typically begin to gently saturate
 the signal for high inputs.
 Although “rail-to-rail” op-amps are available, ones that can run comfortably
 on 3V are expensive.
 A better solution will be to power the op-amps with 5V, then limit the
 output with a clipping circuit.
\end_layout

\begin_layout Standard
To that end, the filter op-amps will be [fix] op amps.
 These have a reasonably low equivalent input voltage noise of 0.8µVrms,
 a passable slew rate of 5V/µs , and can be operated as low as +-2V (or
 4V single ended).
 
\end_layout

\begin_layout Standard
Thus, the input block specs will be as follows: 
\end_layout

\begin_layout Itemize
Input RF (low pass) filter
\end_layout

\begin_deeper
\begin_layout Itemize
Transfer function = 1st order 
\end_layout

\begin_layout Itemize
Filter topology = passive RC 
\end_layout

\begin_layout Itemize
Cutoff = -3dB at 50kHz
\end_layout

\end_deeper
\begin_layout Itemize
Input High pass Filter 
\end_layout

\begin_deeper
\begin_layout Itemize
Input impedance = 5k Ohms 
\end_layout

\begin_layout Itemize
Output impedance = 5k ohms 
\end_layout

\begin_layout Itemize
Transfer function = 2nd order Butterworth 
\end_layout

\begin_layout Itemize
Filter topology = Sallen-and-Key 
\end_layout

\begin_layout Itemize
Cutoff = -6dB at 20kHz
\end_layout

\end_deeper
\begin_layout Itemize
Input Low pass Filter 
\end_layout

\begin_deeper
\begin_layout Itemize
Input impedance = 500k Ohms 
\end_layout

\begin_layout Itemize
Output impedance = 5k Ohms 
\end_layout

\begin_layout Itemize
Transfer function = 3rd-order Butterworth 
\end_layout

\begin_layout Itemize
Filter topology = 1-opamp “Sallen- Key” 
\end_layout

\begin_layout Itemize
Cutoff = -3dB at or slightly below 20 Hz
\end_layout

\end_deeper
\begin_layout Itemize
Preamp stage 
\end_layout

\begin_deeper
\begin_layout Itemize
Input impedance = 500k Ohms 
\end_layout

\begin_layout Itemize
Output impedance < (60k/10) Ohms 
\end_layout

\begin_layout Itemize
Gain range = 0-30dB 
\end_layout

\begin_layout Itemize
Amplifier topology = traditional non-inverting
\end_layout

\end_deeper
\begin_layout Itemize
Output High pass Filter 
\end_layout

\begin_deeper
\begin_layout Itemize
Input impedance < 100 ohms
\end_layout

\begin_layout Itemize
Output impedance ~ 5k ohms 
\end_layout

\begin_layout Itemize
Transfer function = 2nd order Butterworth 
\end_layout

\begin_layout Itemize
Filter topology = Sallen-Key 
\end_layout

\begin_layout Itemize
Cutoff = -6dB at 20kHz 
\end_layout

\end_deeper
\begin_layout Standard
The ADC will be a breakout board based on the Texas Instruments PCM1801.
 This IC is a single-ended sigma-delta ADC designed for cheap embedded audio
 applications.
 It requires both 5V power for the analog section, and 3.3V from the digital
 section.
 The input can swing between 0V and 3V max, with the stipulation that it
 is a single ended ADC, which means that all prior op-amp circuits need
 to be biased to output centered at 1.5VDC.
 Additionally, all op-amps prior to the ADC need to be “comfortable” working
 with a single-ended supply voltage of 5V and signals up to 3V.
 It outputs digital words in I2S or left-justified format.
 For this project, I will be using the I2S format.
\end_layout

\begin_layout Standard
The DAC will be a breakout board based on the Texas Instruments PCM5102A.
 This IC is a single-ended sigma-delta DAC designed for cheap embedded audio
 applications.
 Unlike the ADC, this one only needs 3.3V for both sections.
\end_layout

\begin_layout Standard
Both the ADC and DAC are stereo devices, meaning that there are actually
 two inputs and outputs.
 Stereo operation is unnecessary for most instruments.
 Guitar is inherently monophonic, although some guitar reverbs and ping-pong
 delay effects take advantage of stereo audio.
 In order for the input to be stereo, a user needs to use a stereo effect
 before going into my pedal.
 Although this is plausible, it would make a lot more sense to use my pedal
 to implement that effect.
 Stereo reverb plugins are a dime a dozen, as are ping-pong delays and any
 modulation effect, which stereo operation is often used for.
 Thus, the input will be sent to one of the ADC inputs, and the other will
 be left unconnected.
 On the other hand, the outputs will be sent as stereo outputs.
 Unfortunately, that means the low-pass filter and output gain control will
 have to be matched.
 C’est la vie.
\end_layout

\begin_layout Standard
After some closer reading of the Raspberry Pi’s specs, there is absolutely
 no way that a standard guitar pedal power supply will be sufficient to
 power the Raspberry Pi 4.
 These supplies, even the nicest ones, can typically only offer a few hundred
 mA of current.
 Keep in mind, the guitarist might want to drive other electronics on the
 pedalboard, such as a tuner, noise gate, or unique analog pedal for which
 no digital simulation exists.
 The Raspberry Pi 4 requires a whopping 3A of current, albeit at only 5V.
 Moving to a smaller model of Pi will not fix the problem.
 For comparison, the Electrosmash Pedal-Pi uses the Raspberry Pi Zero, which
 still requires 1A of current, and all other components essentially inherit
 all the power from the Raspberry Pi.
 Additionally, my understanding is that, according to Raspberry Pi documentation
, the safest way to power the device is through the USB port, which is a
 5V connection.
\end_layout

\begin_layout Standard
The system will be controlled primarily with the touchscreen, but secondarily
 through various knobs and switches external to the device.
 Right now, I have planned three digital knobs (rotary encoders), a footswitch
 toggle (separate from the bypass footswitch), an input for an expression
 pedal, and one sampled analog knob.
 Although designs vary wildly, to the point that there is not even a standard
 pinout, the basic principle of operation of an expression pedal is that
 a voltage is placed across a potentiometer operating as a voltage divider,
 whose action is controlled by the lever position.
 (There will also be at least an extra discrete resistor to limit the flow
 of current.) The Raspberry Pi will supply the input voltage and a MicroChip
 MCP3008 ADC (separate from the audio ADC) will convert the signal to SPI
 for the Raspberry Pi.
 This ADC is only 10 bits with a maximum of 200kHz sample frequency, although
 the limitations of SPI make such high rates impractical for the Pi.
 From experience, expression pedal outputs are nearly DC.
 If a user rocks the pedal back and forth 32 times in a second, that would
 yield a frequency of 32Hz, which allows for a Nyquist rate of 64Hz.
 Rounding up 100 Hz provides a guard band for aliasing.
 Note that this is a generous specification; a user who needs to oscillate
 the pedal will be better off doing so using software or an external MIDI
 CC pedal.
 The initial design will accommodate the pinout of a specific expression
 pedal, although the goal will be to implement a multi-position toggle switch
 that switches between the set of a few of the most common ones.
 
\end_layout

\begin_layout Standard
The touchscreen will be a Waveshare 4-Inch screen.
 The video output will be sent through HDMI, and control from the touch
 screen will be sent to the Pi via SPI.
 The touch screen requires both 3.3V power and 5V power.
\end_layout

\begin_layout Standard
My plan to distribute power is to, like the Pedal-Pi, use the on-board 3.3V
 and 5V pins to supply all the necessary power.
 Specifically, besides the nominal voltages, I need a 1.5V biasing voltage
 for all my op-amp filters.
 The Raspberry Pi’s 3.3V and 5V sources must also be filtered, as they are
 notoriously noisy.
 The USB port is used only for power, and cannot be used to access the device,
 so it seems feasible to simply present the USB port to the user on the
 outside of the case to plug into the power supply of their choosing.
 
\end_layout

\begin_layout Standard
The operating system will be the newest version of Raspberry Pi OS.
 Raspberry Pi OS is a derivative of Debian, which itself is a distribution
 of GNU/Linux.
 I will experiment with recompiling the OS with a modified real-time kernel,
 but if I cannot do so, the kernel will be the default.
 In general, music computers do not have real-time operating systems, even
 those at the highest-end studios, for the simple reason that Windows is
 not a real-time operating system.
 The average latency of Windows with a powerful enough CPU can be optimized
 nearly to zero, but it cannot be given an upper bound for 
\emph on
all
\emph default
 operations to finish.
 Practically, this means that Windows can choose not to prioritize the audio
 thread and allow it to miss a sample, which cerates clicks and pops that
 can damage speakers and the eardums of listeners.
 It is a bit difficult to quantify how powerful a CPU needs to be, but it
 depends heavily on the number and type of effects being processed.
 That being said, it has been possible for over a decade to play instruments
 through a typical office computer.
\end_layout

\begin_layout Standard
All versions of the GNU/Linux kernel include the ALSA (Advanced Linux Sound
 Architecture) API (application programming interface).
 When properly configured, it provides kernel-level support for sound devices
 to interact with software.
 It can interface with multiple input and output devices, as well as provide
 support for MIDI synthesis.
 To control and use inputs provided by ALSA, a JACK (JACK Audio Connection
 Kit) audio server must be started.
 It is from here that the user can set inputs and outputs, and where sample
 rate and bit depth can be controlled, if those bit depths are available.
 JACK is, from experience, indispensable for low-latency audio work.
 All that is left from here is the VST host.
 Several valid choices for VST host exist, and the one which I have chosen
 for now is the Carla audio plugin host.
 Carla is a free and open source modular plugin host.
 It can run plugins in VST format as well as those in the LADSPA, DSSI,
 LV2, AU, and JSFX formats.
 When supplied with the correct drivers, architecture emulation, and Windows
 API emulation, it can run VST plugins compiled on Windows and GNU/Linux,
 for x86 or x64 architectures.
 Specifically, a software called WINE (WINE Is Not an Emulator) is used
 to emulate Windows API calls.
 To use a Windows program on GNU/Linux, one typically installs the program
 through WINE, then runs it through WINE every time it needs to be used.
 The Raspberry Pi 4B uses a CPU with an ARM64 instruction set architecture.
 Consequently, x86 and x64 emulation is required.
 The software to provide this is Box86 and Box64, respectively.
\end_layout

\begin_layout Standard
Unfortunately, I have had some trouble in getting Carla to detect the Windows
 API emulation and processor architecture emulation currently installed
 on the Pi.
 Because there is a pre-compiled version of Carla for Windows, if all else
 fails, then I will simply install the Windows version onto the system through
 WINE.
 This technique would force the entire program through WINE, as opposed
 to specific components.
 The user would also lose compatibility for plugins compiled to run on GNU/Linux
 distributions.
 However, to the best of my knowledge, no VST plugins are exclusively designed
 for GNU/Linux.
 The only plugins that are native to GNU/Linux are really those that were
 designed early in the development of the operating system, where it was
 not yet feasible to run through compatibility layers.
 
\end_layout

\begin_layout Standard
Additionally, I am looking to modify the source code of Carla slightly to
 add in dedicated bypass switches.
 Right now, effects can be bypassed with MIDI CC inputs or by setting their
 respective “Wet” knob to zero, but in my view, there is nothing so helpful
 as a bypass switch.
 Additionally, I would like to see if it is feasible to implement my controls
 without sending MIDI CC inputs, which might somehow get sent to instruments
 further down the chain.
 Modifying the program is perfectly acceptable, as the program is licensed
 under GNU GPL-2.0 license.
 Basically, so long as the derivative work inherits the freedoms the license
 originally granted and states that it is modified, it is legal to copy,
 modify, and redistribute the file, possibly for money.
 (Any code I write or modify will be made freely available to the public
 the moment I think it is safe for another user to use.) 
\end_layout

\begin_layout Standard
I will also investigate the use of the Ardour DAW as a plugin host.
 The DAW is free-as-in-speech and open source.
 Ardour can host GNU/Linux compiled VST2 plugins, but with Carla embedded
 as a plugin, it can host all the plugins Carla can.
 Ardour is a fully featured digital audio workstation (DAW), and it is comparabl
e to REAPER or ProTools.
 For a guitarist, Carla on its own would be an easier solution with a shallower
 learning curve, but for a recording engineer who plays guitar, Ardour would
 offer the most flexibility.
 
\end_layout

\begin_layout Standard
To make turning on the pedal a “turn-key operation,” Raspberry Pi OS needs
 to be programmed to do several things upon startup.
 Firstly, ALSA needs to be set to take input from and send output to the
 Raspberry Pi’s I2S ports.
 Next, it would be helpful to boot into a desktop environment.
 This way, in case anything goes wrong, the user has a “friendlier” desktop
 environment from which they can either reboot or reopen closed programs.
 Next, a JACK server needs to be started that takes in I2S input and spits
 out I2S output.
 Finally, a plugin host such as Carla needs to be opened with settings that
 make sense.
 Most obviously, Carla needs to be pointed to the JACK server, but it might
 make sense to load in a default session where the input is sent directly
 to output with an “identity operator” plugin that does nothing to demonstrate
 to the user how to add in a plugin.
 What will likely happen is that I will set up a default project file for
 Carla to load that has all the desired settings and plausibly some (bypassed)
 plugins ready to be enabled.
 If Ardour is used, a default project file would also be set up so that
 a single track is “record enabled” and set to -0dB, feeding a master track
 also set at -0dB, which means that there will be no attenuation or processing
 in general on behalf of Ardour until the user adds some.
\end_layout

\begin_layout Standard
Include hardware block diagram with power sources - mandatory.
  
\end_layout

\begin_layout Standard
For the sake of readability, the power and bias wires have been colored.
 Specifically, 5V power is red, 3.3V power is green, and 1.5V bias for the
 op-amps are blue.
 Signal and control wires are black.
 For the rotary encoders, these will be completely separate GPIO inputs,
 but the diagram was getting cluttered.
 Basically, power will ultimately be handled by the Raspberry Pi 4, and
 the input and output op amps will need to be biased with +1.5VDC.
 Currently, the Pi uses a 5V 3A wall wart that plugs directly into the power
 supply USB port.
 
\end_layout

\begin_layout Chapter
Preliminary Work
\end_layout

\begin_layout Standard
The primary work was research into filter design and audio circuit idiosyncrasie
s that are not obvious and were not covered in depth in previous coursework.
 Most important is that op-amps do not act like ideal linear devices even
 for audio purposes, and that op-amp selection is one of the most important
 factors in how an audio design is going to work out.
 Specifically, finding low-power op amps that are not too noisy has been
 a challenge.
 
\end_layout

\begin_layout Standard
Besides that, the Raspberry Pi OS has been installed onto my Pi, and attempts
 were made to install the x86 and Windows compatibility software.
 
\end_layout

\begin_layout Standard
Additionally, I loaded a version of Carla onto my device from a binary compiled
 for “Debian”.
 It needs to be recompiled as support for a wide range of plugins is currently
 missing, likely due to dependency issues.
 As previously mentioned, I was able to get it to work with a small set
 of plugins.
 It was able to process a few JS plugins in cascade without noticeable latency.
 
\end_layout

\begin_layout Chapter
Components
\end_layout

\begin_layout Standard
Things I have 
\end_layout

\begin_layout Itemize
Raspberry Pi 4 Model B 
\end_layout

\begin_layout Itemize
ADCs (PCM1808 and MCP3008) 
\end_layout

\begin_layout Itemize
Resistors (1/4W and 1/2W, 0-1Mohm) 
\end_layout

\begin_layout Itemize
Electrolytic Capacitors Film 
\end_layout

\begin_layout Itemize
Capacitors Linear and audio-taper potentiometers and plastic knobs 
\end_layout

\begin_layout Itemize
Op amps 
\end_layout

\begin_layout Itemize
Touch screen
\end_layout

\begin_layout Itemize
M-Audio EX-P expression pedal 
\end_layout

\begin_layout Itemize
DAC (PCM5102) 
\end_layout

\begin_layout Itemize
XLR-1/4in combination jack
\end_layout

\begin_layout Standard
Things I need 
\end_layout

\begin_layout Itemize
Metal case 
\end_layout

\begin_layout Chapter
Updated Project Schedule
\end_layout

\begin_layout Standard
Assume Week 0 is that which starts on 01/17/2022 Task or 
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Milestone
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Week
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Finalize design of input filters, input preamp, output post-amp, and output
 filter
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Build input and output circuitry
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Implement touch screen
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Finalize audio software
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Design and build control network, including software
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Design and build expression inputs 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Drill holes in case, place everything into the case
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Chapter
Test
\end_layout

\begin_layout Chapter
Test
\end_layout

\begin_layout Chapter
Test
\end_layout

\begin_layout Chapter
Test
\end_layout

\begin_layout Standard
stuff
\end_layout

\begin_layout Chapter*
\start_of_appendix
Appendices
\end_layout

\begin_layout Standard
The following appendices have been added to provide context for the project
 and to move details that some readers will not be interested in to the
 back.
 Some have been written to satisfy academic requirements, and some have
 been written to compile knowledge for later reference.
 
\end_layout

\begin_layout Chapter
Definitions and Acronyms
\end_layout

\begin_layout Standard
This appendix lists the definitions of jargon, what any acronyms or shorthand
 stand for, and any assumptions in their usage that apply to the entire
 document.
\end_layout

\begin_layout Itemize
UE-DEP
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
U
\series default
ser Extensible-
\series bold
D
\series default
igital 
\series bold
E
\series default
ffects 
\series bold
P
\series default
edal.
 
\end_layout

\begin_layout Itemize
Tentatively pronounced "yoo dehp"
\end_layout

\begin_layout Itemize
Name of this project and its GitHub repo.
 
\end_layout

\end_deeper
\begin_layout Itemize
DSP
\end_layout

\begin_deeper
\begin_layout Itemize
digital signal processing
\end_layout

\begin_layout Itemize
In this project, the DSP will mostly be one-dimensional audio signal processing
 where the signal is assumed to have negligible bandwidth below 20Hz and
 above 20kHz.
 
\end_layout

\begin_layout Itemize
I am assuming that the main input type is electric guitar or *any signal
 derived from it.* 
\end_layout

\end_deeper
\begin_layout Itemize
Discrete time
\end_layout

\begin_deeper
\begin_layout Itemize
Used to describe a signal that is only defined for integer time values or
 at times 
\begin_inset Formula $t_{n}$
\end_inset

 where 
\begin_inset Formula $n$
\end_inset

 is any integer.
\end_layout

\begin_layout Itemize
Uniform sampling is assumed throughout the project.
 Therefore, 
\begin_inset Formula $t_{n}=nT$
\end_inset

 where 
\begin_inset Formula $T=\frac{1}{f_{s}}$
\end_inset

 is a fixed sample rate and 
\begin_inset Formula $f_{s}$
\end_inset

 is the sample frequency.
\end_layout

\end_deeper
\begin_layout Itemize
Digital 
\end_layout

\begin_deeper
\begin_layout Itemize
Used to describe a signal that is Discrete in both time and *allowed values.*
 The latter is typically expressed by saying the signal is "quantized".
 
\end_layout

\begin_layout Itemize
All audio signals are represented on computers as digital signals where
 the allowed values are quantized to be one of 
\begin_inset Formula $2^{N}$
\end_inset

 values, where N is the bit depth (usually 16, 24, or 32).
\end_layout

\begin_layout Itemize
A control history of the on-off state of a push-button switch is represented
 as a digital signal where the allowed values are 1 or 0; or, the signal
 can be one of 
\begin_inset Formula $2^{1}=2$
\end_inset

 values, which can be represented with 1 bit.
 
\end_layout

\end_deeper
\begin_layout Itemize
Bit depth
\end_layout

\begin_deeper
\begin_layout Itemize
The number of bits needed to express all the possible amplitude levels a
 digital signal is allowed to be.
 For example, if a signal can be one of 
\begin_inset Formula $2^{6}=64$
\end_inset

 values, then the bit depth is 6 bits.
\end_layout

\end_deeper
\begin_layout Itemize
Sample frequency
\end_layout

\begin_deeper
\begin_layout Itemize
The number of times a waveform is sampled per second
\end_layout

\begin_layout Itemize
The sample frequency must be at least twice the highest expected frequency
 in the waveform.
\end_layout

\end_deeper
\begin_layout Itemize
RPi 
\end_layout

\begin_deeper
\begin_layout Itemize
Raspberry Pi
\end_layout

\begin_layout Itemize
Although in my project I will be using the Raspberry Pi 4, the hardware
 schematics should work for any microcontroller with i2S capability, 3V3
 logic, and possibly control pin remappings.
\end_layout

\end_deeper
\begin_layout Itemize
OS 
\end_layout

\begin_deeper
\begin_layout Itemize
Operating system
\end_layout

\end_deeper
\begin_layout Itemize
Real-time
\end_layout

\begin_deeper
\begin_layout Itemize
[Firm real-time](https://en.wikipedia.org/wiki/Real-time_computing#Criteria_for_re
al-time_computing)
\end_layout

\end_deeper
\begin_layout Itemize
FOSS 
\end_layout

\begin_deeper
\begin_layout Itemize
free and open source software using the 
\begin_inset CommandInset href
LatexCommand href
name "GNU Free Software Definition"
target "https://www.gnu.org/philosophy/free-sw.html.en#fs-definition"
literal "false"

\end_inset

.
\end_layout

\end_deeper
\begin_layout Itemize
DAW
\end_layout

\begin_deeper
\begin_layout Itemize
A digital audio workstation (DAW) is a class of software that allows a user
 to manipulate digital audio streams, usually using real-time digital effects.
\end_layout

\begin_layout Itemize
Examples:
\end_layout

\begin_deeper
\begin_layout Itemize
ProTools
\end_layout

\begin_layout Itemize
REAPER
\end_layout

\begin_layout Itemize
Ardour
\end_layout

\begin_layout Itemize
Logic
\end_layout

\begin_layout Itemize
Garageband
\end_layout

\begin_layout Itemize
FL Studio
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Audio plugin
\end_layout

\begin_deeper
\begin_layout Itemize
A piece of software designed to extend the signal processing functionality
 of a DAW.
\end_layout

\begin_layout Itemize
Examples
\end_layout

\begin_deeper
\begin_layout Itemize
SimpleEQ - open-source linear equalizer that I wrote
\end_layout

\begin_layout Itemize
ReaEQ - REAPER's stock linear EQ, also available as a free plugin for any
 DAW
\end_layout

\begin_layout Itemize
Ignite Amps Emissary - A simulation of a high-gain amplifier based on a
 real valve amplifier.
 The real amplifier was only ever manufactured for the customer who ordered
 it, whereas the plugin is free to download from their website.
\end_layout

\begin_layout Itemize
Rosen Digital's Pulse - An impulse response convolution plugin designed
 to simulate the modified frequency response imparted to a guitar signal
 by the combination of the speaker, microphone, mic placement, and room.
 Practically, this allows a guitarist to record electric guitar parts without
 micing ujp a cabinet.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Plugin host 
\end_layout

\begin_deeper
\begin_layout Itemize
Any program capable of running at least one format of standard audio plugins
\end_layout

\begin_layout Itemize
For the purpose of this project, an "audio plugin host" will refer to a
 DAW that is not necessarily designed to permanently record input or output
 to a file.
 
\end_layout

\begin_layout Itemize
Examples
\end_layout

\begin_deeper
\begin_layout Itemize
VSTHost
\end_layout

\begin_layout Itemize
Nanohost
\end_layout

\begin_layout Itemize
Carla
\end_layout

\begin_layout Itemize
JUCE's AudioPluginHost
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Cabinet
\end_layout

\begin_deeper
\begin_layout Itemize
Technically, the cabinet is the box that holds a speaker in place
\end_layout

\begin_layout Itemize
Musicians typically refer to the entire speaker-cabinet assembly as a 
\begin_inset Quotes eld
\end_inset

cabinet
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Guitar cabinets have a tailored frequency response motivated by the fact
 that guitar is considered a 
\begin_inset Quotes eld
\end_inset

mid-range
\begin_inset Quotes erd
\end_inset

 instrument.
\end_layout

\end_deeper
\begin_layout Itemize
Micing
\end_layout

\begin_deeper
\begin_layout Itemize
Pronounced 
\begin_inset Quotes eld
\end_inset

mike-ing
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
The process of strategically placing a microphone in front of a sound source
 to record it
\end_layout

\end_deeper
\begin_layout Itemize
JUCE
\end_layout

\begin_deeper
\begin_layout Itemize
Jules' Utility Class Extensions
\end_layout

\begin_layout Itemize
A cross-platform C++ application framework
\end_layout

\begin_layout Itemize
Allows programmers to write code once and compile anywhere
\end_layout

\begin_layout Itemize
Includes extensive support for audio plugins
\end_layout

\begin_layout Itemize
JUCE plugins tend to 
\begin_inset Quotes eld
\end_inset

play nice
\begin_inset Quotes erd
\end_inset

 on multiple platforms
\end_layout

\end_deeper
\begin_layout Chapter
Subsystem Design Documents
\end_layout

\begin_layout Standard
This appendix goes over the technical design of each individual subcomponent.
 Besides the math and parameter values, I will also describe how the circuit
 operates and the justifications for choosing the individual parts.
 The main body of the report will contain abridged explanations of the circuits
 and their working.
 Colloquially, this appendix serves as the 
\begin_inset Quotes eld
\end_inset

long version
\begin_inset Quotes erd
\end_inset

 of those passages.
 The appendix is written with the assumption that the reader is proficient
 in the analysis of linear circuits
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
A linear circuit is one where the circuit equations for an appropriate set
 of variables can be put into the form of a 
\emph on
linear system of differential equations
\emph default
.
 Practically, this means that circuits may have resistors, capacitors, inductors
, ideal voltage and current sources, sources that depend linearly on circuit
 variables, ideal or non-ideal transformers, opamps if saturation is neglected,
 or any legitimate connection of the above.
\end_layout

\end_inset

 with the Laplace and Fourier transform methods, as well as an understanding
 of basic electronic circuits for small signals.
\end_layout

\begin_layout Standard
The approach here is based on the premise that the subsystems are electrically
 and logically distinct.
 For example, the input high-pass filter operates on a voltage and outputs
 a filtered voltage.
 Its design is independent from the input low-pass filter and preamp.
 For each of these circuits, a Thevenin or Norton equivalent circuit can
 be used at the input and a generic load impedance at the output to design
 the circuit.
\end_layout

\begin_layout Standard
Particularly, the other components do not depend meaningfully on the fact
 that the DSP unit is a Raspberry Pi.
 Any microcomputer or microcontroller that has i2s capability and 3V3 logic
 can be substituted into these circuits 
\emph on
without modifying the circuit
\emph default
.
 In this Appendix, the DSP Unit will be treated as a generic integrated
 circuit, except in its dedicated subsection (
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:DSP-unit"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
\end_layout

\begin_layout Standard
The block diagram has been reproduced below:
\end_layout

\begin_layout Standard
[insert BD]
\end_layout

\begin_layout Section
The audio signal chain and bypass
\end_layout

\begin_layout Standard
The audio signal chain refers to the linear path an audio signal will take
 assuming the pedal is not bypassed.
 The bypass circuit takes the pedal 
\begin_inset Quotes eld
\end_inset

out of the loop.
\begin_inset Quotes erd
\end_inset

 It is operated by a stomp-style toggle switch.
\end_layout

\begin_layout Subsubsection
Audio Input Connectors
\end_layout

\begin_layout Paragraph
Preamp
\end_layout

\begin_layout Standard
The basis of the preamp will be a standard non-inverting amplifier, where
 the feedback resistor will be partially replaced by a potentiometer that
 can be adjusted by the performer.
 The gain range will be 0dB
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
As a reminder, 0dB translates to no gain.
 
\emph on
This does not mean that the signal is muted.

\emph default
 The signal will simply propagate at whatever level it left the guitar.
\end_layout

\end_inset

 at its lowest to 30dB at its greatest.
 Most guitars have a volume knob
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Technically, one could build a guitar without one.
 Otherwise, all guitars made for sale have volume knobs.
\end_layout

\end_inset

, so attenuating the signal is possible from there.
 Muting the signal should be done with the bypass switch.
\end_layout

\begin_layout Standard
Because the ADC is single-ended, the preamp also needs to bias the incoming
 audio signal.
 Audio signals can be positive or negative.
 If a negative signal is sent to the ADC, it will off the negative swing.
 This will be perceived as audible distortion.
\end_layout

\begin_layout Standard
Lastly, the input impedance of this stage will be the impedance 
\begin_inset Quotes eld
\end_inset

seen
\begin_inset Quotes erd
\end_inset

 by the guitar.
 Input impedance affects how the guitar 
\begin_inset Quotes eld
\end_inset

feels.
\begin_inset Quotes erd
\end_inset

 More accurately, the guitar's circuit interacts with the circuitry of the
 other signal processing elements.
 This interaction can be heard by the guitarist in the way their guitar
 sounds and how it changes with respect to changes in playing technique.
\end_layout

\begin_layout Paragraph
High Pass
\end_layout

\begin_layout Standard
The purpose of the high-pass filter is to remove low-frequency garbage that
 corrupts the audible part of the signal with worthless signal energy.
 Practically, a high-pass-filtered signal sounds clearer and better defined.
 Additionally, guitar speakers can be permanently damaged by large low frequency
 excursions.
 This is especially a problem for bassists playing through guitar speaker
 cabinets.
 
\end_layout

\begin_layout Paragraph
Low Pass
\end_layout

\begin_layout Standard
The purpose of the low-pass filter is to enforce Shannon's sampling theorem
 to avoid audible distortion caused by aliasing.
 Practically, this means attenuating out-of-band frequencies to below the
 size of 1 LSB (least significant bit) for the ADC.
\end_layout

\begin_layout Standard
The fundamental note of a guitar signal will not exceed about 4kHz, and
 even this is a high estimate.
 That being said, it is plausible that a guitarist might use an analog distortio
n pedal 
\emph on
in front
\emph default
 of the pedal.
 Typically, a distortion pedal adds, besides even and odd order harmonics,
 a bunch of crossover terms.
 [Add RS-MET proof] This results in a noisy spectrum for almost all notes
 on the guitar.
 Thus, the pedal needs to allow the transmission of all the frequencies
 that are required to retain the sound of an average distortion pedal.
\end_layout

\begin_layout Standard
The answer to this question admittedly begins with a subjective ballpark
 judgement of the required frequency response by applying a low-pass to
 various distortion effects and seeing how low I can set the frequency before
 losing important qualities of the distortion.
 What I came up with is that the cutoff can be set around 10kHz.
 The best explanation I can offer relies on the fact that 
\begin_inset Quotes eld
\end_inset

Presence
\begin_inset Quotes erd
\end_inset

 controls on high-gain guitar amplifiers are typically analog filters that
 cut or boost high frequencies with a resonant peak (or dip) between 5kHz-10kHz.
 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Incidentally, this is typically where I and most other audio mixers place
 a software high-pass when processing high-gain guitar.
 Audio engineers typically learn how to set high-passes and other filters
 
\begin_inset Quotes eld
\end_inset

by ear
\begin_inset Quotes erd
\end_inset

 directly in the digital domain with an audio plugin.
 Even with my signals and systems knowledge, I find this to be the most
 reliable way to determine a cutoff frequency (at least for audible signals).
\end_layout

\end_inset

 From my experience of dialing in dozens of high-gain amplifiers and distortion
 pedals, I have learned that correctly setting the Presence control (when
 it is there) is one of the most important ways for a guitar track to cut
 through the mix.
 In a typical rock or metal mix, this frequency band is sparsely populated
 other than the band of guitar distortion affected by the Presence control.
 My hypothesis is that this frequency band is where listeners (subconsciously)
 
\begin_inset Quotes eld
\end_inset

look
\begin_inset Quotes erd
\end_inset

 for distorted guitar when more important frequency bands are masked by
 other instruments.
\end_layout

\begin_layout Paragraph
ADC
\end_layout

\begin_layout Standard
The ADC is a breakout board based on the TI PCM1808 integrated circuit.
 The PCM1808 is an oversampling converter that uses a 
\begin_inset Formula $\Sigma\Delta$
\end_inset

 architecture.
 [Explain that].
 It converts audio data to serialized binary using the i2s protocol.
\end_layout

\begin_layout Subsubsection
DSP unit
\begin_inset CommandInset label
LatexCommand label
name "subsec:DSP-unit"

\end_inset


\end_layout

\begin_layout Standard
The DSP unit is the Raspberry Pi 4 either running a plugin host or send
 input to output (e.g., implementing the identity system).
 The Pi is unmodified, and it is running 64-bit RPi OS.
\end_layout

\begin_layout Subsubsection
Audio Output
\end_layout

\begin_layout Paragraph
DAC+Headphone Amplifier
\end_layout

\begin_layout Standard
The DAC+Amplifier is a breakout board based on the TI PCM5102 integrated
 circuit.
 The PCM5102 converts i2s binary signals to a continuous audio waveform.
 There is a headphone amplifier built into the board.
 The schematic for the breakout board has been reproduced below.
 
\end_layout

\begin_layout Paragraph
Preamp
\end_layout

\begin_layout Standard
The basis of the preamp will be a standard non-inverting amplifier, where
 the feedback resistor will be partially replaced by a potentiometer that
 can be adjusted by the performer.
 
\end_layout

\begin_layout Paragraph
High Pass
\end_layout

\begin_layout Standard
The purpose of the high-pass filter is similar to the input high-pass.
 
\end_layout

\begin_layout Paragraph
Low Pass
\end_layout

\begin_layout Standard
The purpose of the low-pass filter is to ensure that inaudible frequencies
 do not take up useless signal energy or possibly affect other digital gear
 down the line.
 This time, the filter cutoff really needs to be quite close to 20kHz, because
 it is absolutely plausible that a guitarist might either pitch-shift their
 guitar or add heavy harmonic distoriton in the DSP unit.
\end_layout

\begin_layout Standard
Additionally, this circuit will set the output impedance seen by an amplifier,
 guitar pedal, or audio interface.
 Consequently, it must lie within a interval of 
\begin_inset Quotes eld
\end_inset

expected
\begin_inset Quotes erd
\end_inset

 values that are 
\begin_inset Quotes eld
\end_inset

much smaller than
\begin_inset Quotes erd
\end_inset

 the input impedance of subsequent stages.
\end_layout

\begin_layout Section
The control bank
\end_layout

\begin_layout Standard
The control bank is the set of external controls that can be mapped to plugin
 parameters.
 Each subcomponent in the bank is independent from the others.
\end_layout

\begin_layout Subsection
Expression Pedal Input
\end_layout

\begin_layout Standard
An expression pedal is a variable voltage divider where the ratio is set
 by the angle of the rocker.
 Expression pedals are used by performers to modulate pedal parameters while
 their hands are occupied playing guitar.
 To interface with the DSP unit, the voltage at the divider needs to be
 converted to a number within a range.
 This is accomplished with a [insert other ADC here].
 This converts a slowly-changing signal to an integer transmitted as a serialize
d binary signal with the i2C protocol.
\end_layout

\begin_layout Subsection
Rotary Encoder
\end_layout

\begin_layout Standard
The rotary encoder will be simply implemented with a ready-made 24-position
 rotary encoder.
\end_layout

\begin_layout Subsection
Push button
\end_layout

\begin_layout Standard
The push button will be implemented with an ordinary push-button switch
 and a pullup resistor in the following configuration:
\end_layout

\begin_layout Section
The touch screen
\end_layout

\begin_layout Section
Power distribution
\end_layout

\begin_layout Chapter
Licenses
\end_layout

\begin_layout Standard
As a designer, I am not interested in imposing any restrictions upon the
 usage of my software.
 However, because of the nature of the Copyright system and the FOSS licenses
 of several software components in this project, it is not as simple as
 merely releasing the work into the public domain without any copyright.
\end_layout

\begin_layout Standard
Very briefly, most FOSS software uses some type of 
\emph on
copyleft
\emph default
 licensing.
 The idea of copyleft licenses is to 
\emph on
require
\emph default
 those who use parts of the 
\end_layout

\begin_layout Standard
As a developer, the constraints imposed by free software licenses are a
 mild annoyance that requires me to check that the licenses are compatible
 with my work.
 Because I spend a lot more time as a consumer of open-source software,
 I am pleased to know that I am free to use their software as I please.
 I would like to extend this freedom to users of my project or any of its
 potential derivatives.
\end_layout

\begin_layout Section
Plagiarism
\end_layout

\begin_layout Standard
According to NJIT's University Policy on Academic Integrity, plagiarism
 is defined as follows:
\end_layout

\begin_layout Quotation
Plagiarism is defined as: Using or attempting to use written, oral, or graphic
 work which was authored or prepared by another and submitting it as one’s
 own without appropriate citation or credit.
 Intentionally or knowingly representing the words or ideas of another as
 one’s own in any academic exercise.
 It is also a combination of stealing and lying about it afterwards.
\end_layout

\begin_layout Standard
Thus, in order to conform to the University's academic standards, all software
 utilized will be listed.
 Note that software typically depends on other software.
 FOSS licenses require, by virtue of the inheritence of user freedoms, all
 software used to be either FOSS or able to be used as part of the software
 whenever that software is used.
 To save time tracking down all the dependencies and their individual licenses,
 I will be listing the licenses of top-level software only.
 Those pieces of software are, as per the construction of copyleft licenses,
 required to internally show the licenses for their own dependencies.
 For example, it is not necessary to cite the license for the Linux kernel
 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
unless the kernel is modified!
\end_layout

\end_inset

 because it is a dependency of the Raspberry Pi OS.
 In this case, Raspberry Pi OS is responsible for conforming to the licenses
 of their software.
 Indeed, Raspberry Pi OS includes all the licenses and their content embedded
 in the default installation of their operating system.
\end_layout

\begin_layout Standard
Lastly, attribution is 
\emph on
not
\emph default
 required to legally use FOSS in a project for most licenses.
 I need to explicitly attribute my works in order to conform to the University's
 academic policy.
 Also, I would like to credit the people who made my project possible.
\end_layout

\begin_layout Chapter
Introduction to Music Production
\end_layout

\begin_layout Section
Audio terminology and standard workflow
\end_layout

\begin_layout Standard
Once a song is written and the performers know how to play it, the song
 is recorded.
 Typically, this is achieved by having the band play their parts while their
 instruments are recorded by a set of microphones.
 There is usually at least one microphone per "instrument", and several
 for the drum kit.
 Unless the engineer sums the outputs of the microphones before the conversion
 to digital (which might commit serious phase issues to "tape"; so it is
 never done), each microphone will record to one track of a multitrack recorder.
\end_layout

\begin_layout Standard
Historically, a multitrack recorder was literally a bank of reel-to-reel
 tape recorders, which were summed in the analog domain.
 This practice survives in a different form: the "multitrack metaphor" in
 the design of digital audio workstations.
 If the entire band is recorded as a single performance, then all the microphone
 inputs will be sent to distinct ADC's, which will convert the audio signals
 to a multichannel digital signal in a specially designed low-latency audio
 interface.
 (Basically, the audio interface is an audio input or output where a driver
 that circumvents the operating system's default driver is used.) Unless
 the engineer permanently sums the tracks in the digital domain, each track
 will be recorded to a separate uncompressed digital audio file.
\end_layout

\begin_layout Standard
Despite all the steps involved in this process, this can be easily done
 in real time.
 Actually, we often add real-time effect plugins to the tracks, and we also
 send the digital audio back out to the performers where, after an obligatory
 DAC, they use this audio to monitor their performance.
\end_layout

\begin_layout Standard
In short, audio tracks are recorded and converted to digital individually.
 These audio files are processed by either analog gear or digital plugins,
 then digitally summed with weights decided by the engineer.
 The process of preparing the tracks for summing and balancing the weights
 is called mixing.
 After mixing, the track is taken to a professional with nice analog gear
 and a deep understanding of audio for mastering, which prepares the final
 recording for distribution.
\end_layout

\begin_layout Standard
This is not some idealized, theoretical concept of audio production.
 In fact, this is the typical workflow of a modern budget studio.
 In the modern day, almost no information is lost from coversion between
 digital and analog, or vice versa, even in low end consumer devices.
 Basically, so long as it is "designed for audio," it is a safe bet that
 the ADCs and DACs are practically transparent.
 It would take a spectacularly incompetent engineer to release an audio
 output that sounds "digital" today.
\end_layout

\begin_layout Standard
For home studios and bedroom bands, the process is modified slightly.
 Because consumers typically lack the hardware and inputs to record an entire
 band, the band might take turns recording parts with one or two microphones
 or direct inputs.
 The first band member, typically the drummer, records to a click track,
 which ensures a consistent tempo.
 Then, each band member records on top of the previous musicians work in
 a new track.
\end_layout

\begin_layout Standard
Higher-end studios do use analog gear because they can afford to do so.
 However, the vast majority of processing will still be in the digital domain
 because, if used competently, digital systems can sound just as good as
 analog ones.
\end_layout

\begin_layout Standard
A particularly helpful example is the linear equalizer.
 Assuming a perfect performance and everything else is perfect, a real track
 needs, at the bare minimum, high-passes and low-passes to get rid of low-
 and high-frequency garbage and help separate the different instruments.
 Although nearly linear equalizers can be built in the analog domain, they
 are expensive and difficult to design.
 Digital linear equalizers are a dime a dozen, almost perfectly linear,
 and use trivial CPU.
 Crucially, an engineer can insert as many concurrent real-time instances
 of a digital EQ plugin as they desire.
 An analog equalizer will usually have two stereo inputs, so to use it on
 more than two tracks, an engineer needs to convert the tracks back to analog,
 play them through the equalizer, and rerecord and convert the tracks back
 into the digital domain.
 Although this process is not worth the effort for an equalizer, it can
 make good sense to rerecord guitar amps and vintage dynamics processors,
 especially if there is no plugin emulation for the particular analog element.
 Still, for analog gear that has a plugin counterpart, it is much easier
 to use the digital version.
 A common occurance is when an engineer is handed a vocal track recorded
 in an untreated room, and as a result has unwanted resonance corresponding
 to the room modes.
 A linear EQ is typically dialed in to provide a narrow cut at the resonant
 frequency.
 This preserves the character of the vocal track while removing the room
 mode.
 Then, the engineer can process the track further without having to worry
 about the room mode.
\end_layout

\begin_layout Standard
Except for a handful of purists, audio engineers will reach for whatever
 tool provides the best sound for the job.
 In high-end studios, there is just as much chance of the engineer reaching
 for a piece of analog gear as there is of the engineer adding a premium
 plugin to the channel strip in their DAW.
 It is in fact access to the latter that budget studios will often advertise
 as their selling point.
\end_layout

\begin_layout Standard
The reason why all this is relevant for my project is that in the early
 2000's, bands that could afford it began to use high-end laptops running
 mixing software as effect processors.
 For example, Periphery is a progressive metal band that inserts digital
 effects into their guitar signal chain to give their guitar sound an "electroni
c" timbre for small parts of the song.
 Because they do most of their effect processing digitally using the same
 signal chain as they used in the studio, their live performances sound
 very close to their albums.
\end_layout

\begin_layout Standard
My concept is to create a dedicated device to process guitar signals using
 existing audio plugins for live usage.
 One goal is to allow a musician to 
\begin_inset Quotes eld
\end_inset

drag-and-drop
\begin_inset Quotes erd
\end_inset

 their signal chain into my box and play through it in real time.
 Another is to create a platform where makers can write and test audio DSP
 algorithms in context with the rest of their hardware signal chain.
\end_layout

\begin_layout Section
Subjectivism in digital audio
\end_layout

\begin_layout Standard
The thesis of this section is that while my pedal should be able to produce
 
\begin_inset Quotes eld
\end_inset

correct
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

good-sounding
\begin_inset Quotes erd
\end_inset

 outputs in a way that can be emprically measured, there will always be
 a class of people who intrinsically reject digital audio technology and
 cannot be convinced (even with evidence) that my pedal can help them.
 
\end_layout

\begin_layout Standard
In philosophy, 
\emph on
subjectivism
\emph default
 is a group of related doctrines that view human knowledge in some field
 of endeavor as purely subjective, and that no objective truth about the
 field exists.
 The result is that an individual's subjective experience is valued over
 empirical evidence, possibly including that which contradicts an individual's
 beliefs.
 For example, an artistic subjectivist would view that there is no objective
 way to determine whether a piece of art is 
\begin_inset Quotes eld
\end_inset

good
\begin_inset Quotes erd
\end_inset

, and that the quality of art is only intrinsically determined by the viewer.
 This application of subjectivism is not controversial; in contrast, moral
 subjectivism has been the center of centuries of heated debate.
 Consequently, we cannot simply drop or accept subjectivism without some
 degree of consideration for the underlying field.
\end_layout

\begin_layout Standard
In the sciences, it is widely accepted that there exists some objective
 truth.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
At a bare minimum, there is something so common to all our experiences that
 it ought be treated as objective reality.
 For example, almost everyone knows that releasing an apple in the air will
 cause it to fall towards the ground.
 Therefore, the existence of gravity as a phenomenon is effectively an objective
 truth, although its mechanism is not understood by all people.
\end_layout

\end_inset

 Specifically, there are laws of physics, and they can be accurately described
 by Newton's laws and the associated mathematical equations.
 This is the position taken in this project: that audio phenomena can be
 objectively measured
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Whether or not the quality of a sound 
\emph on
as music
\emph default
 can be objectively measured is separate from measuring physical audio phenomena
, and irrelevant for the project.
\end_layout

\end_inset

.
 A consequence of this viewpoint is the rejection of the existence of audio
 phenomena that cannot possibly be measured or quantified
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
To be clear, whether or not an individual is personally competent enough
 to measure the phenonmenon is not what is being considered.
 It is whether a measurement instrument of suitable precision and a competent
 operator could verify that the phenomenon exists.
 Measurability is a necessary but insufficient quality for existence.
 For example, the 21 grams experiment 
\begin_inset Quotes eld
\end_inset

measured
\begin_inset Quotes erd
\end_inset

 the weight of the soul to be 21 grams, yet the sample size was too small
 to conclude anything about the value of the weight or the correlation between
 the weight differential and the existence of the soul.
 
\end_layout

\end_inset

 Unfortunately, a large subset of people, particularly those who are the
 most vocal about the importance of 
\begin_inset Quotes eld
\end_inset

quality
\begin_inset Quotes erd
\end_inset

 sound systems, are 
\emph on
audio subjectivists
\emph default
.
 Consequently, these people are inherently distrustful of scientifically
 minded people who might make measurements that invalidate their opinions.
\end_layout

\begin_layout Standard
The problem with audio subjectivism is that there actually are phenomena
 that are difficult (but not impossible) to measure with standard equipment.
 The human ear is a ridiculously sensitive instrument, and it can detect
 very small vibrations.
 The ear can detect very small nonlinearities in the frequency response
 of an otherwise linear audio system compared to other fields in signal
 processing.
 Musicians with their ear training make that instrument even more sensitive.
 They have probably been told several times that something they can clearly
 hear does not exist by someone who claims to be an authority figure or
 domain expert.
 How often is such an interaction followed by whipping out an SPL meter
 and checking that the sound exists? Rarely, if ever.
 The problem of debunking audio subjectivism is that the concerns of its
 adherents 
\emph on
are valid and likely based in reality.

\emph default
 Unfortunately, it might be a reality that is mathematically complicated
 or driven by a poorly understood mechanism.
\end_layout

\begin_layout Standard
The continued usage of analog music gear in place of digital implementations
 is one of the most important examples of audio subjectivism in the modern
 era.
 One of the reasons that analog gear has persisted amongst musicians is
 precisely because of the variability of analog parameters.
 Two nominally equivalent analog pedals might sound subtlely different.
 Consequently, there is a sense of uniqueness and individuality that comes
 with owning an analog pedal.
 For vacuum-tube-based gear, this is especially true, as vacuum-tube gear
 will audibly dull over the life of the tube, which can be noticed over
 a period of a few weeks of heavy usage.
 Quantifying the variability of these parameters is a difficult and subtle
 topic that is not of interest to most people.
 Through a misuse of Occam's razor, because the unmeasureable, intrinsic
 
\begin_inset Quotes eld
\end_inset

analog sound
\begin_inset Quotes erd
\end_inset

 seems just as reasonable to a musician unaquainted with electronics, 
\begin_inset Quotes eld
\end_inset

analog sound
\begin_inset Quotes erd
\end_inset

 is a simpler explanation and therefore the one worth adopting.
 For musicians this is mostly harmless, but audio designers must understand
 what makes analog gear sound good in order to compete with it.
\end_layout

\begin_layout Standard
For musicians who consider the authenticity of their analog gear to be a
 part of their art, no bit depth or sample frequency will ever be high enough
 to make the switch to digital worthwhile, because their pedal is metaphysically
 unique.
 Because of this, many musicians reject digital gear and cannot be convinced
 otherwise.
\end_layout

\begin_layout Standard
For musicians who can at least tolerate a part of their signal chain being
 digital, Shannon's sampling theorem provides most of the answer.
 For linear processing, sampling at 44.1kHz ensures that the entire audible
 range is captured with about 2kHz as a buffer.
 For nonlinear processing, digital oversampling can be (and usually is)
 used.
 This is usually baked into the particular audio plugin that needs it.
 For practical purposes, anything that can be done in the analog domain
 can be done in the digital domain without creating any artefacts, so long
 as the plugin designer is competent.
 (Really, we can achieve an arbitrarily good approximation, so good that
 the artefacts are inaudible.) This does not account for the idiosyncratic
 behavior of analog devices.
 These need to be added to digital audio systems manually if they are desired.
 
\end_layout

\begin_layout Standard
The issues arise for plugins that attempt to model specific pieces of analog
 gear.
 The problem is to optimally discretize a nonlinear circuit model.
 Although the problem is theoretically simple, the actual implementation
 requires the plugin designer to choose function approximations that yield
 good results around the operating point in the fastest possible time.
 Although the feasibility of analog modeling plugins is considered a solved
 problem, there is still a lot of research to be done in testing fast nonlinear
 approximations.
\end_layout

\begin_layout Standard
However, analog emulating plugin technology has come a long way.
 Even ten years ago, emulations of the major distortion pedals, amplifiers,
 and matched speaker cabinets were indistinguishable from their analog versions
 in the mix.
 This is still very much the case for the most popular plugins.
\end_layout

\begin_layout Standard
This is not a hypothetical scenario.
 All sorts of wild pseudoscience has cropped up around audio system design,
 particularly in the "audiophile" community where things like "passive preamps"
 are regularly sold to people supersitious about the intrinsic worth of
 analog electronics.
 The experiences of artists and consumers of art are based upon their subjective
 evaluations of the media they consume.
 As I have demonstrated above, it is not much of a stretch to think that
 audio systems design is also a subjective field, since it is adjacent to
 music.
 
\end_layout

\begin_layout Standard
Of course, as I hope to demonstrate, audio system design is mostly an objective
 field driven by data and physical princples.
 Objectively good electronic system design, combined with subjective decisions
 about the user interface and intentional "imperfections" in the signal
 chain, are the ingredients that yield a quality sound system.
\end_layout

\begin_layout Standard
In summation, for those who absolutely cannot tolerate a single piece of
 digital gear in their signal chain:
\end_layout

\begin_layout Quotation
"You can lead a horse to water, but you can't make it drink."
\end_layout

\begin_layout Standard
I hope to establish their trust in the future by releasing the code for
 this project and all my audio work as free and open-source software, to
 show them that there's nothing to hide.
 For everyone else, I hope my pedal serves as a useful tool.
\end_layout

\begin_layout Chapter
Introduction to Audio Plugins
\end_layout

\begin_layout Section
The purpose of the SimpleEQ plugin.
\end_layout

\begin_layout Standard
The SimpleEQ plugin was initially written as a way to pass the time while
 waiting for the ball to drop on New Years' Eve.
 The reason why I have brought it into the project is because it is a specific
 example of an audio plugin whose processing I fully and unambiguously understan
d, because I wrote it.
 This plugin really is the bare minimum that the system should be able to
 handle.
 It will serve as the first plugin to be tested.
 Because I have all the project files, and because I wrote it with the JUCE
 framework, it is a trivial matter to cross-compile the project for any
 target operating system and architecture.
\end_layout

\begin_layout Subsubsection
Principle of operation
\end_layout

\begin_layout Standard
Audio is processed in blocks that are determined by the plugin host.
 This sample block size can usually be set by the user, and it is made as
 small as the CPU can handle before the block size exceeds the amount of
 time it takes to process the block.
\end_layout

\begin_layout Standard
The DSP algorithm is a cascade of generic 2nd-order IIR Butterworth filters
 and a resonant peak.
 The Butterworth filters are 
\begin_inset Quotes eld
\end_inset

low cut
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

high cut
\begin_inset Quotes erd
\end_inset

 (high-pass and low-pass respectively
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
In audio, the 
\begin_inset Quotes eld
\end_inset

cut
\begin_inset Quotes erd
\end_inset

 terminology is typically preferred because that is why an audio mixing
 engineer typically applies a high/low-pass filter: to remove or 
\begin_inset Quotes eld
\end_inset

cut out
\begin_inset Quotes erd
\end_inset

 low frequencies.
 In this section, the 
\begin_inset Quotes eld
\end_inset

cut
\begin_inset Quotes erd
\end_inset

 terminology will be used, but in the rest of the UE-DEP project, the 
\begin_inset Quotes eld
\end_inset

pass
\begin_inset Quotes erd
\end_inset

 terminology is used.
\end_layout

\end_inset

).
 The plugin generates filter coefficients based on the frequency and steepness
 settings stored in the plugin's state, and it transforms one set of coefficient
s to the corresponding low-cut coefficients.
 The resonant peak is generated based on the frequency, gain, and Q parameters
 stored in the plugin's state.
 The plugin convolves an audio buffer with each filter response in cascade.
\end_layout

\begin_layout Standard
While this occurs, the GUI operates on a separate thread.
 The GUI looks for changes to its parameters, then sends any changes to
 the plugin's state.
 The new state will take effect when the next audio buffer is processed.
 The plugin host can also change parameters through 
\emph on
automation
\emph default
 if the user so chooses.
 For example, the gain of the peak filter can be set to respond to the amplitude
 of the audio signal.
\end_layout

\begin_layout Standard
The program structure, where audio processing and user control are handled
 by different threads and communicate through an external plugin state,
 is common to almost all plugins in all formats.
 Any plugin written with the JUCE framework begins with an automatically
 generate template of this structure.
 Consequently, these are the functions a plugin host, and consequently my
 hardware platform, needs to be capable of supporting.
\end_layout

\begin_layout Section
What exactly is a 
\emph on
VST
\emph default
 Plugin?
\end_layout

\begin_layout Standard
[Explain]
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
According to Wikipedia:
\end_layout

\begin_layout Quotation
\begin_inset Quotes eld
\end_inset

A simulation is the imitation of the operation of a real-world process or
 system over time
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
An audio plugin is not 
\emph on
intrinsically
\emph default
 a simulation.
 This fact is the principle that drives this project.
 For example, the SimpleEQ plugin is not a simulation of an equalizer; it
 
\emph on
is
\emph default
 an equalizer.
 Running a piece of audio through this pedal will affect the frequency response
 according to the indicated filter characteristic.
 The only practical difference between using the plugin with ADC and DAC
 and using an (ideal) analog equalizer with the same transfer function is
 that the digital one introduces a time delay of 
\begin_inset Formula $2^{N}$
\end_inset

 samples.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Formula $2^{N}$
\end_inset

 represents the size of the audio buffer in samples.
 Practically, the audio buffer is chosen to be as small as the CPU can handle.
 It is set by the plugin host.
 Other plugins can introduce their own latency depending on their programming,
 but the latency caused by the audio buffer is only applied once.
 Typical values are between 16 and 1024 samples.
 For a 48kHz sample rate, it is not advised to use a buffer larger than
 48 samples 
\begin_inset Formula $\left(=48\text{k}\frac{\text{samples}}{\text{s}}\times1\text{ms}\right)$
\end_inset

if the CPU allows, although guitarists can typically put up with slightly
 higher values than musicians who play other instruments.
\end_layout

\end_inset

 The memory locations the plugin host assigns 
\emph on
are
\emph default
 where the process of mixing music and modifying audio data actually occurs.
\end_layout

\begin_layout Standard
That being said, 
\emph on
many
\emph default
 audio plugins are simulations of some piece of analog gear.
 For example, the TSE808 plugin is a model of a specific Tube Screamer pedal.
 Most of the plugins I use are models of specific pieces of analog gear.
 However, this is not the case for all plugins.
 As a counterexample, all the filters in SimpleEQ are discrete-time IIR
 versions of the 2nd order Butterworth transfer function.
 These filters could be realized in the analog domain by designing Butterworth
 filters using a filter coefficient table and cascading the indivdual filter
 sections, but 
\emph on
this plugin was not derived from an already existing analog circuit
\emph default
.
 The goal was to implement the discrete time filter in the digital domain.
 Still, the frequency responses and nonlinear system functions of analog
 gear still provide inspiration for plugin algorithms because these are
 the sounds to which listeners have been acclimated.
\end_layout

\begin_layout Chapter
Operating Systems and How They Affect This Design
\end_layout

\begin_layout Standard
This appendix is a vast oversimplification of how the existence of several
 operating systems influenced the design of the system.
 The facts are recounted in broad terms as they are relevant to the project.
\end_layout

\begin_layout Standard
The operating system is a piece of software that manages other applications
 and provides common services for them.
 Examples of operating systems include Windows 10, Mac OS X, Debian, and
 Raspberry Pi OS.
 A crucial component of any operating system is its 
\emph on
kernel
\emph default
, which manages low-level tasks.
 For example, the common element amongst all GNU/Linux operating systems
 is their dependence on a version of the Linux kernel.
 For this reason, different Linux-based operating systems are often called
 distributions.
 For example, Raspberry Pi OS is a modified Debian distribution.
\end_layout

\begin_layout Section
The relation between Operating Systems and Processor Architectures
\end_layout

\begin_layout Standard
There are many processor architectures, but the ones that are important
 for this project are x86, x64, and ARM64.
 x64 is the 
\begin_inset Quotes eld
\end_inset

typical
\begin_inset Quotes erd
\end_inset

 architecture for 64-bit desktop computers using Intel or AMD CPUs.
 x86 is the older 32-bit version of the Intel/AMD architecture.
 ARM64 is the 64-bit version of the ARM architecture typical of mobile and
 embedded devices.
\end_layout

\begin_layout Standard
GNU/Linux is the term for the group of FOSS operating systems that use the
 Linux kernel.
 For the purpose of audio work, the source code of a 
\begin_inset Quotes eld
\end_inset

Linux
\begin_inset Quotes erd
\end_inset

 plugin will compile on any GNU/Linux OS so long as all its dependencies
 are installed.
 However, depending on the complexity of the plugin, pre-compiled binaries
 might not work for all Linux systems.
 In that case, developers will typically release a bunch of binaries compiled
 for the 
\begin_inset Quotes eld
\end_inset

mainstream
\begin_inset Quotes erd
\end_inset

 Linux-based operating systems.
 People using specialized GNU/Linux distributions can often get away with
 using the mainstream binaries if their distribution was forked from one
 of the main ones.
 (For example, Debian binaries will usually run on RPi OS because RPi OS
 was forked from Debian).
 It is up to each developer of a GNU/Linux operating system to release separate
 binaries of their operating system for each processor architecture they
 wish to support.
 In the case of RPi OS, the OS is available for x86, x64, and ARM64 architecture
s, as well as 32-bit ARM.
\end_layout

\begin_layout Standard
Windows is a proprietary, closed source operating system.
 Most versions of Windows can be built for x86 and x64 architectures.
 Special versions of Windows exist for ARM architectures, but these are
 never used for audio work.
 For the purposes of this project, Windows software can be built for either
 the x86 or x64 architectures.
\end_layout

\begin_layout Standard
For the highest-end studios, Mac OS X is the operating system of choice
 because of its integration with ProTools and other Avid products, and the
 status that can be broadcasted by owning an expensive Apple computer.
 However, for even remotely budget-conscious studios that typically cannot
 afford Avid and Apple products, Windows is the operating system of choice
 for audio production.
 (Anecdotally, it is currently my choice for audio production.) Although
 it is the absolute worst OS for low-latency audio work out of the box,
 most manufacturers supply Windows drivers to circumvent the OS's native
 audio manager.
 Additionally, most audio programs (including ProTools) support Windows
 systems.
 Most people use Windows on their office and gaming computers anyway, so
 the transition to their audio PC is more seamless.
\end_layout

\begin_layout Section
Raspberry Pi 4 is ARM64-based
\end_layout

\begin_layout Verse
The Raspberry Pi 4 has a CPU with an 
\emph on
ARM64
\emph default
 processor architecture.
\end_layout

\begin_layout Standard

\series bold
The importance of this fact cannot be understated.

\series default
 The reason why the RPi 4 was chosen was because it has excellent documentation,
 it is accessible for makers and musicians, and because it has 8GB of RAM
 and a fast processor.
 I could not find a comparable x86 microcomputer with a similar amount of
 RAM or comparable processor.
 In order to support the vast majority of audio plugins, there needs to
 be 
\emph on
software
\emph default
 support for x86 and x64
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
64-bit support is prioritized over 32-bit support because 32-bit operating
 systems are going the way of the dinosaur.
 Many plugin developers have stopped releasing 32-bit binaries for their
 plugins altogether.
\end_layout

\end_inset

 system calls.
 
\end_layout

\begin_layout Standard
When I graduated from recording school (2016), professional audio on Linux
 was simply impractical.
 Our curriculum included no mention of Linux.
 The main issue with audio on Linux at that time was a lack of audio programs
 comparable to those available for Windows and OS X.
 Even back then, the problem of latency was mostly solved at the system
 level with the integration of ALSA into Linux and the development of JACK
 for low-latency audio routing.
 WINE did exist and had decent support for modern video games and office
 applications, but the technology was not quite ready for pro audio.
\end_layout

\begin_layout Standard
Windows emulation has come a very long way since then.
 As if to demonstrate to the world how far such emulation had come, in 2020
 the Valve Corporation released a game console based around a heavily modified
 distribution of Arch Linux.
 This is aimed at mainstream consumers looking to play games 
\emph on
developed for PC
\emph default
 on a Windows system.
 So far, the system has been quite successful.
 It demonstrates that real-time operations comparable to those expected
 of a powerful desktop PC are possible on Linux.
\end_layout

\begin_layout Standard
For this project, the important development is the release of the Carla
 plugin host.
 Carla can be built with bridges to WINE and x86/64 emulators to allow the
 host to use plugins compiled for Windows.
\end_layout

\begin_layout Section
How Computer Programs Work
\end_layout

\begin_layout Standard
The workflow to implement a computer program is as follows:
\end_layout

\begin_layout Enumerate
Write the code in a programming language as a text file.
 
\end_layout

\begin_layout Enumerate
Compile the source code into assembly language.
\end_layout

\begin_layout Enumerate
Link together assembly code and libraries into an executable.
 
\end_layout

\begin_layout Standard
The assembly language in Step 2 depends on the processor's instruction set
 architecture.
 Step 1 could be dependent on the operating system if the programmer uses
 APIs that are unique to a platform.
 Steps 2 and 3 are usually abstracted away by the IDE, which is preconfigured
 by default to compile for the host operating system.
\end_layout

\begin_layout Standard
An audio plugin is a compiled binary file with functions that are called
 by the audio host as they are needed.
 Because the binary file is compiled for a target platform, all plugin binaries
 are at least restricted to run on the processor architecture for which
 the programmer chose to compile it.
 Usually, x86 and x64 versions of plugins are offered as precompiled binaries.
 Because the plugin contains GUI data, the compliled plugins usually rely
 on operating-system specific API calls unless a unifying framework like
 JUCE is used.
 (Even when using JUCE, the plugin needs to specifically compiled for each
 target platform, although there usually are no meaningful changes to the
 source code.
 The change is in the linked libraries provided by JUCE.) JUCE is increasingly
 adopted by audio developers.
\end_layout

\begin_layout Section
The Approach for Supporting Audio Plugins
\end_layout

\begin_layout Standard
The support of audio plugins is the same as support for software in general,
 so I will discuss the topic in general terms.
\end_layout

\begin_layout Standard
Consequently, there are eight possible classes of software to support:
\end_layout

\begin_layout Enumerate
Compiled for ARM 
\end_layout

\begin_deeper
\begin_layout Enumerate
64-bit 
\end_layout

\begin_deeper
\begin_layout Enumerate
Windows (unheard of) 
\end_layout

\begin_layout Enumerate
GNU Linux (Raspberry Pi) 
\end_layout

\end_deeper
\begin_layout Enumerate
32-bit 
\end_layout

\begin_deeper
\begin_layout Enumerate
Windows (unheard of) 
\end_layout

\begin_layout Enumerate
GNU Linux (Raspberry Pi w/ 32-bit OS) 
\end_layout

\end_deeper
\end_deeper
\begin_layout Enumerate
Compiled for Intel/AMD
\end_layout

\begin_deeper
\begin_layout Enumerate
64-bit
\end_layout

\begin_deeper
\begin_layout Enumerate
Windows (most common) 
\end_layout

\begin_layout Enumerate
GNU Linux (rare but increasing) 
\end_layout

\end_deeper
\begin_layout Enumerate
32-bit 
\end_layout

\begin_deeper
\begin_layout Enumerate
Windows (common in the past) 
\end_layout

\begin_layout Enumerate
GNU Linux (rare, unlikely for new plugins)
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
The easiest class to support is ARM64-GNU Linux.
 This includes plugins compiled for Raspberry Pi directly.
 32-bit ARM binaries are supported on 64-bit Raspberry Pi OS.
 Regardless, I am not aware of any plugin manufacturer who actually releases
 ARM binaries.
\end_layout

\begin_layout Standard
Next, we have the two classes of 32- and 64-bit "Intel" architectures with
 a GNU Linux target OS.
 These are currently supported.
 This is accomplished by the box86 and box64 libraries that translate x86
 and x64 system calls (respectively) into ARM.
 Carla is aware of these libraries, and consequently can load plugins compiled
 for GNU Linux in any architecture.
\end_layout

\begin_layout Standard
Support for 32-bit Windows plugins has been suboptimally implemented by
 installing a 32-bit Windows plugin host with ASIO drivers that runs in
 WINE.
 However, my goal is to compile Carla with the Windows plugin bridges.
 These would fully support x86 and x64 Windows plugins.
 Contingency plans for the various types of plugins are detailed in the
 Plan section.
\end_layout

\begin_layout Standard
At a bare minimum, the pedal can currently run GNU Linux plugins compiled
 for any "mainstream" target architecture.
 This opens the door for a variety of FOSS plugins.
 Paid and proprietary plugins are typically released for Windows.
\end_layout

\begin_layout Standard
The focus will be on implementing VST-formatted plugins.
 This is the most common format, and it is the format-du-jeur of consumer-grade
 (and consumer-priced) audio plugins.
 If Carla is used, it will be easy to support the FOSS plugin formats for
 GNU Linux.
\end_layout

\begin_layout Standard
I have no intent to support AAX plugins because developers need to pay Avid
 for the rights to develop software in their format.
 Every other plugin format is free to develop.
 Frankly, I have no use for AAX-only plugins as a musician or audio developer,
 and I advise that audio engineers avoid AAX-only plugins for any purpose.
\end_layout

\begin_layout Chapter
Git, GitHub, Version Control, and their Role in Maintaining This Project
\end_layout

\begin_layout Standard
Very briefly, my project will be hosted on GitHub.
 Project progress can be monitored by checking through the edit history
 of the 
\begin_inset CommandInset href
LatexCommand href
name "project's GitHub repository."
target "https://github.com/gg232/UE-DEP"
literal "false"

\end_inset


\end_layout

\begin_layout Standard
This Appendix is included so I can discuss Git concepts clearly with my
 adviser or anyone else interested in my project.
\end_layout

\begin_layout Section
An explanation of Git
\end_layout

\begin_layout Standard

\emph on
Version control
\emph default
 software is a tool that tracks the changes to a group of files.
 For example, if a programmer adds code to a project that breaks the project,
 then saves the project and publishes it to the internet, then the project
 will be broken.
 To fix the error, the programmer has to look through the source code of
 the project and remove the error directly.
 For complex projects, it might not be obvious which code was broken.
 If several programmers are involved in the project, it will be difficult
 to point out how one programmer changed the project.
\end_layout

\begin_layout Standard

\emph on
Git
\emph default
 is the most popular version control software.
 It is available for practically any modern operating system.
 Git works by tracking the changes to files and subdirectories within a
 directory
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
On Windows systems, a directory is usually called a 
\emph on
folder
\emph default
, and a subdirectory is called a 
\emph on
subfolder
\emph default
.
\end_layout

\end_inset

 by using a 
\emph on
tree
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
In graph theory, a tree is a minimal set of branches such that, by traversing
 only the branches in the tree, all nodes in the graph can be reached.
 Basically, Git implements this graph, and allows the user to traverse the
 graph by either committing data or reverting previous commits (undo).
\end_layout

\end_inset


\emph default
 representation.
 Because source code files are typically plain text files with unique file
 extensions, Git can track the changes in source code files and other compressed
 text files.
 It cannot track changes in binaries such as executables, .docx files, and
 .png files, but it can tell if changes have been made, and it can revert
 those files back to their previously saved versions.
 Source files (or anything a programmer wants Git to track) are typically
 saved to online 
\emph on
repositories
\emph default
 (or 
\emph on
repo
\emph default
 for short).
 
\end_layout

\begin_layout Standard
To compile a program from source, the first step is typically to clone the
 Git repository, or copy the files and subdirectory
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
A subdirectory (relative to a parent directory) is a directory contained
 within another directory.
\end_layout

\end_inset

 structure to a local directory of choice.
\end_layout

\begin_layout Standard

\emph on
GitHub
\emph default
 is Microsoft's online repository host.
 Whenever the source code of a project is released online, the code actually
 resides on the servers owned by the repository host (in this project's
 case, GitHub).
 GitHub is a searchable website where most Git features are available for
 viewing.
\end_layout

\begin_layout Standard
To edit a Git repository hosted on GitHub, a programmer fetches the repo
 from GitHub, then works on the contents of the repo on their local machine.
 Once the programmer is ready to commit a change to the online repository,
 it is pushed to GitHub using a unique security code so that only people
 who are allowed to change the repo can do so.
\end_layout

\begin_layout Standard
Because Git stores a tree structure, a programmer can create a branch within
 the original project and work on it independently from the main branch.
 This allows a programmer to make drastic, possibly program-breaking changes
 in their branch without affecting the main branch.
 Practically, this is leveraged by programmers who designate a 
\begin_inset Quotes eld
\end_inset

main
\begin_inset Quotes erd
\end_inset

 branch as the most important or 
\begin_inset Quotes eld
\end_inset

outward facing
\begin_inset Quotes erd
\end_inset

 branch that people can use, and a developement branch (or several) where
 changes can be implemented.
 Once a development branch is debugged to work, it can be 
\emph on
merged
\emph default
 back into the main branch through Git's merge command.
 This allows the programmer to see the changes and where they occur, and
 to approve or reject individual changes.
\end_layout

\begin_layout Section
What files can be managed by Git?
\end_layout

\begin_layout Standard
For any text file with any file extension (or none), the creation of, changes
 within, and deletion of files can be fully tracked.
 This is why the original versions of all documents are written in \SpecialChar LyX

\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\SpecialChar LyX
 is a 
\begin_inset Quotes eld
\end_inset

manuscript editor
\begin_inset Quotes erd
\end_inset

 that generates \SpecialChar LaTeX
 code in a 
\begin_inset Quotes eld
\end_inset

friendlier
\begin_inset Quotes erd
\end_inset

 environment resembling a standard word processor.
\end_layout

\end_inset

: .lyx files are uncompressed text files, so all changes can be tracked with
 Git.
 These files can be easily converted to .tex, .docx, or .odt.
\end_layout

\begin_layout Standard
For any other file (e.g.
 a compressed binary, or just 
\begin_inset Quotes eld
\end_inset

binary
\begin_inset Quotes erd
\end_inset

 for short), Git can track if the file was changed, and what was its binary
 content for the last commit.
 Practically, this means that versions of binaries can be stored, but that
 it cannot tell the programmer exactly which lines were changed.
 Individual changes can not be approved or rejected, but the programmer
 can still choose to accept the changed binary or revert to the old version.
\end_layout

\begin_layout Standard
Explicitly, the following file types are compiled binaries:
\end_layout

\begin_layout Itemize
KiCad files
\end_layout

\begin_layout Itemize
Multisim files
\end_layout

\begin_layout Itemize
Word documents (.docx)
\end_layout

\begin_layout Itemize
Open Document Type documents (.odt)
\end_layout

\begin_layout Standard
The following file types are plain text files who changes can be fully tracked:
\end_layout

\begin_layout Itemize
Ordinary text files (.txt)
\end_layout

\begin_layout Itemize
GitHub markdown files (.md)
\end_layout

\begin_layout Itemize
LyX documents (.lyx)
\end_layout

\begin_layout Itemize
\SpecialChar TeX
 and \SpecialChar LaTeX
 documents (.tex)
\end_layout

\begin_layout Itemize
Executables
\end_layout

\begin_layout Itemize
Dynamic linked libraries (.dll's)
\end_layout

\begin_layout Subsection
What files can be hosted on GitHub?
\end_layout

\begin_layout Standard
GitHub can host any file that Git can track with one crucial exception:
 files must be 
\emph on
under 100MB
\emph default
 for users who have not paid for large file storage.
 Basically, hosted files should be small.
 There is no stated size limitation for entire repos, but GitHub support
 suggests that they stay under 1GB total size.
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
I will be using GitHub to disclose my progress, release the project files,
 and documentation to the public, and 
\emph on
maintain a history of my changes.
\end_layout

\begin_layout Standard
The typical workflow for the project will be to fetch the copy onto whatever
 computer I happen to be using, then create a local WIP (work in progress)
 branch.
 All new work will take place on this branch.
 If I need to interrupt my work or switch computers, the local WIP branch
 will be pushed to the GitHub repo.
 When the WIP branch has reached a point that I am comfortable with the
 
\end_layout

\begin_layout Standard
The GitHub repo for this file is located at the following 
\begin_inset CommandInset href
LatexCommand href
name "hyperlink"
target "https://github.com/gg232/UE-DEP"
literal "false"

\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
In case the hyperlink is broken: https://github.com/gg232/UE-DEP
\end_layout

\end_inset

.
 All code and documentation that I can host will be posted here.
\end_layout

\begin_layout Standard
Note that, as of the writing of this document, the repo is set to 
\emph on
private
\emph default
.
 This means that it will not show up if searched for with GitHub's search
 bar.
 It can be accessed if you have a link to the URL (provided in several locations
 above in this document).
 
\end_layout

\end_body
\end_document
